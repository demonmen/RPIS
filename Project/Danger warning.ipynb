{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.目标检测函数\n",
    "def Target_monitoring(img):\n",
    "    yolo_dir = 'cfg'  # YOLO文件路径\n",
    "    weightsPath = os.path.join(yolo_dir, 'yolov3.weights')  # 权重文件\n",
    "    configPath = os.path.join(yolo_dir, 'yolov3.cfg')  # 配置文件\n",
    "    labelsPath = os.path.join(yolo_dir, 'coco.names')  # label名称\n",
    "\n",
    "\n",
    "    CONFIDENCE = 0.5  # 过滤弱检测的最小概率\n",
    "    THRESHOLD = 0.4  # 非最大值抑制阈值\n",
    "\n",
    "    # 加载网络、配置权重\n",
    "    net = cv.dnn.readNetFromDarknet(configPath, weightsPath)  # #  利用下载的文件\n",
    "\n",
    "\n",
    "    # 加载图片、转为blob格式、送入网络输入层\n",
    "    #img = cv.imread(imgPath)#测试图像\n",
    "\n",
    "    blobImg = cv.dnn.blobFromImage(img, 1.0/255.0, (416, 416), None, True, False)   # # net需要的输入是blob格式的，用blobFromImage这个函数来转格式\n",
    "    net.setInput(blobImg)  # # 调用setInput函数将图片送入输入层\n",
    "    # 获取网络输出层信息（所有输出层的名字），设定并前向传播\n",
    "    outInfo = net.getUnconnectedOutLayersNames()  # # 前面的yolov3架构也讲了，yolo在每个scale都有输出，outInfo是每个scale的名字信息，供net.forward使用\n",
    "    start = time.time()\n",
    "    layerOutputs = net.forward(outInfo)  # 得到各个输出层的、各个检测框等信息，是二维结构。\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"[INFO] YOLO took {:.6f} seconds\".format(end - start))  # # 可以打印下信息\n",
    "\n",
    "    # 拿到图片尺寸\n",
    "    (H, W) = img.shape[:2]\n",
    "    # 过滤layerOutputs\n",
    "    # layerOutputs的第1维的元素内容: [center_x, center_y, width, height, objectness, N-class score data]\n",
    "    # 过滤后的结果放入：\n",
    "    boxes = [] # 所有边界框（各层结果放一起）\n",
    "    confidences = [] # 所有置信度\n",
    "    classIDs = [] # 所有分类ID\n",
    "\n",
    "    # # 1）过滤掉置信度低的框框\n",
    "    for out in layerOutputs:  # 各个输出层\n",
    "        for detection in out:  # 各个框框\n",
    "            # 拿到置信度\n",
    "            scores = detection[5:]  # 各个类别的置信度\n",
    "            classID = np.argmax(scores)  # 最高置信度的id即为分类id\n",
    "            confidence = scores[classID]  # 拿到置信度\n",
    "\n",
    "            # 根据置信度筛查\n",
    "            if confidence > CONFIDENCE:\n",
    "                box = detection[0:4] * np.array([W, H, W, H])  # 将边界框放会图片尺寸\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "\n",
    "    # # 2）应用非最大值抑制(non-maxima suppression，nms)进一步筛掉\n",
    "    idxs = cv.dnn.NMSBoxes(boxes, confidences, CONFIDENCE, THRESHOLD) # boxes中，保留的box的索引index存入idxs\n",
    "    # 得到labels列表\n",
    "    with open(labelsPath, 'rt') as f:\n",
    "        labels = f.read().rstrip('\\n').split('\\n')\n",
    "    labels = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple']\n",
    "    # 应用检测结果\n",
    "    np.random.seed(42)\n",
    "    COLORS = np.random.randint(0, 255, size=(len(labels), 3), dtype=\"uint8\")  # 框框显示颜色，每一类有不同的颜色，每种颜色都是由RGB三个值组成的，所以size为(len(labels), 3)\n",
    "    if len(idxs) > 0:\n",
    "        for i in idxs.flatten():  # indxs是二维的，第0维是输出层，所以这里把它展平成1维\n",
    "            if(labels[classIDs[i]] == 'person'):\n",
    "                (x, y) = (boxes[i][0], boxes[i][1])\n",
    "                (w, h) = (boxes[i][2], boxes[i][3])\n",
    "                color = [int(c) for c in COLORS[classIDs[i]]]\n",
    "                cv.rectangle(img, (x, y), (x+w, y+h), color, 2)  # 线条粗细为2px\n",
    "                text = \"{}: {:.4f}\".format(labels[classIDs[i]], confidences[i])\n",
    "                cv.putText(img, text, (x, y-5), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)  # cv.FONT_HERSHEY_SIMPLEX字体风格、0.5字体大小、粗细2px\n",
    "                return img,x,y,w,h\n",
    "    return img,0,0,0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import time\n",
    "sdThresh = 10\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "def distMap(frame1, frame2):\n",
    "    frame1_32 = np.float32(frame1)\n",
    "    frame2_32 = np.float32(frame2)\n",
    "    diff32 = frame1_32 - frame2_32\n",
    "    norm32 = np.sqrt(diff32[:,:,0]**2 + diff32[:,:,1]**2 + \\\n",
    "             diff32[:,:,2]**2)/np.sqrt(255**2 + 255**2 + 255**2)\n",
    "    dist = np.uint8(norm32*255)\n",
    "    return dist\n",
    "\n",
    "cv2.namedWindow('frame')\n",
    "cv2.namedWindow('dist')\n",
    "\n",
    "#capture video stream from camera source. 0 refers to first camera, 1 referes to 2nd and so on.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "_, frame1 = cap.read()\n",
    "_, frame2 = cap.read()\n",
    "\n",
    "facecount = 0\n",
    "while(True):\n",
    "    _, frame3 = cap.read()\n",
    "    rows, cols, _ = np.shape(frame3)\n",
    "    cv2.imshow('dist', frame3)\n",
    "    dist = distMap(frame1, frame3)\n",
    "\n",
    "    frame1 = frame2\n",
    "    frame2 = frame3\n",
    "\n",
    "    mod = cv2.GaussianBlur(dist, (9,9), 0)\n",
    "    _, thresh = cv2.threshold(mod, 100, 255, 0)\n",
    "    _, stDev = cv2.meanStdDev(mod)\n",
    "\n",
    "    cv2.imshow('dist', mod)\n",
    "    cv2.putText(frame2, \"Standard Deviation - {}\".format(round(stDev[0][0],0)), \\\n",
    "                (70, 70), font, 1, (255, 0, 255), 1, cv2.LINE_AA)\n",
    "    if stDev > 2*sdThresh:\n",
    "        cv2.imwrite('doing.jpg',mod)\n",
    "        img = cv2.imread('doing.jpg')\n",
    "        target,x,y,w,h = Target_monitoring(img)\n",
    "        print(x,y,w,h)\n",
    "        cv2.imwrite('target.jpg',target)\n",
    "        focalLength = 557.1428571428571\n",
    "        know_width = 19\n",
    "        know_height = 16\n",
    "        def find_marker(filename):\n",
    "            image = cv2.imread(filename)\n",
    "            gray_img = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "            gaussian_img = cv2.GaussianBlur(gray_img,(5,5),0)\n",
    "            edged_img = cv2.Canny(gaussian_img,35,125)\n",
    "            countours,hierarchy = cv2.findContours(edged_img.copy(),cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "            c = max(countours, key=cv2.contourArea)\n",
    "            rect = cv2.minAreaRect(c)\n",
    "            return rect\n",
    "        def distance_to_camera(knowWidth,focalLength,perWidth):\n",
    "            return knowWidth * focalLength/perWidth\n",
    "        def cal_distance(filename,focalLength):\n",
    "            image = cv2.imread(filename)\n",
    "            marker = find_marker(filename)\n",
    "            distance = distance_to_camera(know_width,focalLength,marker[1][0])\n",
    "            print('距离为：',distance * 2.54)\n",
    "            return distance*2.54\n",
    "        if __name__ == '__main__':\n",
    "            distance = cal_distance('target.jpg',focalLength)\n",
    "            if distance<60:\n",
    "                import winsound\n",
    "                duration = 1000  # millisecond\n",
    "                freq = 440  # Hz\n",
    "                winsound.Beep(freq, duration)\n",
    "                \n",
    "        os.remove('doing.jpg')\n",
    "\n",
    "    cv2.imshow('frame', frame2)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.目标检测函数\n",
    "def Target_monitoring(img):\n",
    "    yolo_dir = 'cfg'  # YOLO文件路径\n",
    "    weightsPath = os.path.join(yolo_dir, 'yolov3.weights')  # 权重文件\n",
    "    configPath = os.path.join(yolo_dir, 'yolov3.cfg')  # 配置文件\n",
    "    labelsPath = os.path.join(yolo_dir, 'coco.names')  # label名称\n",
    "\n",
    "\n",
    "    CONFIDENCE = 0.5  # 过滤弱检测的最小概率\n",
    "    THRESHOLD = 0.4  # 非最大值抑制阈值\n",
    "\n",
    "    # 加载网络、配置权重\n",
    "    net = cv.dnn.readNetFromDarknet(configPath, weightsPath)  # #  利用下载的文件\n",
    "\n",
    "\n",
    "    # 加载图片、转为blob格式、送入网络输入层\n",
    "    #img = cv.imread(imgPath)#测试图像\n",
    "\n",
    "    blobImg = cv.dnn.blobFromImage(img, 1.0/255.0, (416, 416), None, True, False)   # # net需要的输入是blob格式的，用blobFromImage这个函数来转格式\n",
    "    net.setInput(blobImg)  # # 调用setInput函数将图片送入输入层\n",
    "    # 获取网络输出层信息（所有输出层的名字），设定并前向传播\n",
    "    outInfo = net.getUnconnectedOutLayersNames()  # # 前面的yolov3架构也讲了，yolo在每个scale都有输出，outInfo是每个scale的名字信息，供net.forward使用\n",
    "    start = time.time()\n",
    "    layerOutputs = net.forward(outInfo)  # 得到各个输出层的、各个检测框等信息，是二维结构。\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"[INFO] YOLO took {:.6f} seconds\".format(end - start))  # # 可以打印下信息\n",
    "\n",
    "    # 拿到图片尺寸\n",
    "    (H, W) = img.shape[:2]\n",
    "    # 过滤layerOutputs\n",
    "    # layerOutputs的第1维的元素内容: [center_x, center_y, width, height, objectness, N-class score data]\n",
    "    # 过滤后的结果放入：\n",
    "    boxes = [] # 所有边界框（各层结果放一起）\n",
    "    confidences = [] # 所有置信度\n",
    "    classIDs = [] # 所有分类ID\n",
    "\n",
    "    # # 1）过滤掉置信度低的框框\n",
    "    for out in layerOutputs:  # 各个输出层\n",
    "        for detection in out:  # 各个框框\n",
    "            # 拿到置信度\n",
    "            scores = detection[5:]  # 各个类别的置信度\n",
    "            classID = np.argmax(scores)  # 最高置信度的id即为分类id\n",
    "            confidence = scores[classID]  # 拿到置信度\n",
    "\n",
    "            # 根据置信度筛查\n",
    "            if confidence > CONFIDENCE:\n",
    "                box = detection[0:4] * np.array([W, H, W, H])  # 将边界框放会图片尺寸\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "\n",
    "    # # 2）应用非最大值抑制(non-maxima suppression，nms)进一步筛掉\n",
    "    idxs = cv.dnn.NMSBoxes(boxes, confidences, CONFIDENCE, THRESHOLD) # boxes中，保留的box的索引index存入idxs\n",
    "    # 得到labels列表\n",
    "    with open(labelsPath, 'rt') as f:\n",
    "        labels = f.read().rstrip('\\n').split('\\n')\n",
    "    labels = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple']\n",
    "    # 应用检测结果\n",
    "    np.random.seed(42)\n",
    "    COLORS = np.random.randint(0, 255, size=(len(labels), 3), dtype=\"uint8\")  # 框框显示颜色，每一类有不同的颜色，每种颜色都是由RGB三个值组成的，所以size为(len(labels), 3)\n",
    "    if len(idxs) > 0:\n",
    "        for i in idxs.flatten():  # indxs是二维的，第0维是输出层，所以这里把它展平成1维\n",
    "            if(labels[classIDs[i]] == 'person'):\n",
    "                (x, y) = (boxes[i][0], boxes[i][1])\n",
    "                (w, h) = (boxes[i][2], boxes[i][3])\n",
    "                color = [int(c) for c in COLORS[classIDs[i]]]\n",
    "                cv.rectangle(img, (x, y), (x+w, y+h), color, 2)  # 线条粗细为2px\n",
    "                text = \"{}: {:.4f}\".format(labels[classIDs[i]], confidences[i])\n",
    "                cv.putText(img, text, (x, y-5), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)  # cv.FONT_HERSHEY_SIMPLEX字体风格、0.5字体大小、粗细2px\n",
    "                return img,x,y,w,h\n",
    "    return img,0,0,0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import time\n",
    "sdThresh = 10\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "def distMap(frame1, frame2):\n",
    "    frame1_32 = np.float32(frame1)\n",
    "    frame2_32 = np.float32(frame2)\n",
    "    diff32 = frame1_32 - frame2_32\n",
    "    norm32 = np.sqrt(diff32[:,:,0]**2 + diff32[:,:,1]**2 + \\\n",
    "             diff32[:,:,2]**2)/np.sqrt(255**2 + 255**2 + 255**2)\n",
    "    dist = np.uint8(norm32*255)\n",
    "    return dist\n",
    "\n",
    "cv2.namedWindow('frame')\n",
    "cv2.namedWindow('dist')\n",
    "\n",
    "#capture video stream from camera source. 0 refers to first camera, 1 referes to 2nd and so on.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "_, frame1 = cap.read()\n",
    "_, frame2 = cap.read()\n",
    "\n",
    "facecount = 0\n",
    "while(True):\n",
    "    _, frame3 = cap.read()\n",
    "    rows, cols, _ = np.shape(frame3)\n",
    "    cv2.imshow('dist', frame3)\n",
    "    dist = distMap(frame1, frame3)\n",
    "\n",
    "    frame1 = frame2\n",
    "    frame2 = frame3\n",
    "\n",
    "    mod = cv2.GaussianBlur(dist, (9,9), 0)\n",
    "    _, thresh = cv2.threshold(mod, 100, 255, 0)\n",
    "    _, stDev = cv2.meanStdDev(mod)\n",
    "\n",
    "    cv2.imshow('dist', mod)\n",
    "    cv2.putText(frame2, \"Standard Deviation - {}\".format(round(stDev[0][0],0)), \\\n",
    "                (70, 70), font, 1, (255, 0, 255), 1, cv2.LINE_AA)\n",
    "    if stDev > 2*sdThresh:\n",
    "        import winsound\n",
    "        duration = 1000  # millisecond\n",
    "        freq = 440  # Hz\n",
    "        winsound.Beep(freq, duration)\n",
    "        cv2.imwrite('doing.jpg',mod)\n",
    "        img = cv2.imread('doing.jpg')\n",
    "        target,x,y,w,h = Target_monitoring(img)\n",
    "        print(x,y,w,h)\n",
    "        os.remove('doing.jpg')\n",
    "\n",
    "    cv2.imshow('frame', frame2)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
